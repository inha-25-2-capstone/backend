#!/usr/bin/env python3
"""
Test KeyBERT topic generation integration with HF Spaces.

This script tests the /generate-topics endpoint on the deployed AI service
and verifies it works correctly with Korean political news articles.
"""

import sys
from pathlib import Path
import requests
import json
from datetime import datetime

# Add project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.config import AI_SERVICE_URL, AI_SERVICE_TIMEOUT
from src.utils.logger import setup_logger

logger = setup_logger("test_keybert", level="INFO")


def test_health_check():
    """Test /health endpoint to verify service is running."""
    url = f"{AI_SERVICE_URL}/health"
    logger.info(f"Testing health check: {url}")

    try:
        response = requests.get(url, timeout=10)

        if response.status_code == 200:
            result = response.json()
            logger.info("âœ… Service is healthy")
            logger.info(f"   Summarization model: {result.get('summarization_model')}")
            logger.info(f"   Embedding model: {result.get('embedding_model')}")
            logger.info(f"   Device: {result.get('device')}")
            return True
        else:
            logger.error(f"âŒ Health check failed: {response.status_code}")
            logger.error(f"   Response: {response.text}")
            return False

    except Exception as e:
        logger.error(f"âŒ Health check error: {e}")
        return False


def test_generate_topics():
    """Test /generate-topics endpoint with sample Korean news."""
    url = f"{AI_SERVICE_URL}/generate-topics"
    logger.info(f"\nTesting topic generation: {url}")

    # Sample clusters with Korean political news
    test_clusters = [
        {
            "cluster_id": 1,
            "representative_articles": [
                {
                    "title": "ì •ë¶€, ë¶€ë™ì‚° ê·œì œ ì™„í™” ë°œí‘œ",
                    "summary": "ì •ë¶€ê°€ ì£¼íƒë‹´ë³´ëŒ€ì¶œ ê·œì œë¥¼ ì™„í™”í•˜ë©° ë¶€ë™ì‚° ì‹œì¥ í™œì„±í™”ë¥¼ ë„ëª¨í•œë‹¤. ê¸ˆìœµë‹¹êµ­ì€ ëŒ€ì¶œ í•œë„ë¥¼ ìƒí–¥ ì¡°ì •í•˜ê³  ê·œì œì§€ì—­ì„ ì¶•ì†Œí•˜ê¸°ë¡œ í–ˆë‹¤."
                },
                {
                    "title": "ì•¼ë‹¹, ë¶€ë™ì‚° ì •ì±… ë¹„íŒ",
                    "summary": "ì•¼ë‹¹ì€ ì •ë¶€ì˜ ë¶€ë™ì‚° ê·œì œ ì™„í™” ë°©ì•ˆì´ ì„œë¯¼ë“¤ì˜ ì£¼ê±° ë¶ˆì•ˆì„ ê°€ì¤‘ì‹œí‚¬ ê²ƒì´ë¼ê³  ë¹„íŒí–ˆë‹¤. ì§‘ê°’ ìƒìŠ¹ ìš°ë ¤ê°€ ì»¤ì§€ê³  ìˆë‹¤."
                },
                {
                    "title": "ì „ë¬¸ê°€ë“¤, ë¶€ë™ì‚° ì‹œì¥ ì „ë§ ì—‡ê°ˆë ¤",
                    "summary": "ë¶€ë™ì‚° ì „ë¬¸ê°€ë“¤ì€ ì •ë¶€ì˜ ê·œì œ ì™„í™” ì •ì±…ì— ëŒ€í•œ ì‹œì¥ ë°˜ì‘ì´ ì—‡ê°ˆë¦´ ê²ƒìœ¼ë¡œ ì „ë§í–ˆë‹¤. ì¼ë¶€ëŠ” ì‹œì¥ ì•ˆì •í™”ë¥¼, ì¼ë¶€ëŠ” ê°€ê²© ê¸‰ë“±ì„ ì˜ˆì¸¡í–ˆë‹¤."
                }
            ]
        },
        {
            "cluster_id": 2,
            "representative_articles": [
                {
                    "title": "êµ­ì •ê°ì‚¬, ì •ë¶€ ì •ì±… ì ê²€",
                    "summary": "êµ­íšŒì—ì„œ ì •ë¶€ ë¶€ì²˜ì— ëŒ€í•œ êµ­ì •ê°ì‚¬ê°€ ì‹œì‘ëë‹¤. ì—¬ì•¼ ì˜ì›ë“¤ì´ ì •ë¶€ ì •ì±…ì˜ ë¬¸ì œì ì„ ì§€ì í•˜ê³  ê°œì„ ì„ ì´‰êµ¬í–ˆë‹¤."
                },
                {
                    "title": "êµ­ì •ê°ì‚¬ì¥ 'ì„¤ì „'... ì—¬ì•¼ ê³µë°© ê²©í™”",
                    "summary": "êµ­ì •ê°ì‚¬ì¥ì—ì„œ ì—¬ì•¼ ì˜ì›ë“¤ì˜ ì„¤ì „ì´ ì´ì–´ì¡Œë‹¤. ì •ë¶€ ì •ì±…ì„ ë‘˜ëŸ¬ì‹¼ ê³µë°©ì´ ê²©í™”ë˜ë©° ì˜ê²¬ ëŒ€ë¦½ì´ ì‹¬í™”ëë‹¤."
                }
            ]
        },
        {
            "cluster_id": 3,
            "representative_articles": [
                {
                    "title": "í•œë¯¸ êµ­ë°©ì¥ê´€, ë¶í•œ ìœ„í˜‘ ëŒ€ì‘ ë…¼ì˜",
                    "summary": "í•œë¯¸ ì–‘êµ­ êµ­ë°©ì¥ê´€ì´ íšŒë‹´ì„ ê°–ê³  ë¶í•œì˜ êµ°ì‚¬ ìœ„í˜‘ì— ëŒ€í•œ ê³µë™ ëŒ€ì‘ ë°©ì•ˆì„ ë…¼ì˜í–ˆë‹¤. ì–‘êµ­ì€ ì—°í•©ë°©ìœ„íƒœì„¸ë¥¼ ê°•í™”í•˜ê¸°ë¡œ í•©ì˜í–ˆë‹¤."
                },
                {
                    "title": "ë¶í•œ ë¯¸ì‚¬ì¼ ë„ë°œ, ì•ˆë³´ë¦¬ ê·œíƒ„",
                    "summary": "ë¶í•œì˜ ë¯¸ì‚¬ì¼ ë°œì‚¬ì— ëŒ€í•´ ìœ ì—” ì•ˆì „ë³´ì¥ì´ì‚¬íšŒê°€ ê¸´ê¸‰íšŒì˜ë¥¼ ì—´ê³  ê·œíƒ„ ì„±ëª…ì„ ë°œí‘œí–ˆë‹¤."
                }
            ]
        }
    ]

    payload = {
        "clusters": test_clusters,
        "top_n_keywords": 3,
        "keyphrase_ngram_range": [2, 4]
    }

    try:
        logger.info(f"Sending request with {len(test_clusters)} clusters...")
        response = requests.post(
            url,
            json=payload,
            timeout=AI_SERVICE_TIMEOUT
        )

        if response.status_code == 200:
            result = response.json()
            logger.info("âœ… Topic generation SUCCESS")
            logger.info(f"   Clusters processed: {result['total_clusters']}")
            logger.info(f"   Processing time: {result['processing_time_seconds']}s")
            logger.info("\n" + "=" * 80)
            logger.info("GENERATED TOPICS")
            logger.info("=" * 80)

            for topic in result['topics']:
                logger.info(f"\nğŸ“Œ Cluster {topic['cluster_id']}: {topic['topic_title']}")
                logger.info("   Keywords:")
                for kw in topic['keywords']:
                    logger.info(f"     - {kw['keyword']} (score: {kw['score']:.3f})")

            logger.info("\n" + "=" * 80)
            return True

        else:
            logger.error(f"âŒ Topic generation failed: {response.status_code}")
            logger.error(f"   Response: {response.text}")
            return False

    except Exception as e:
        logger.error(f"âŒ Topic generation error: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_with_db_data():
    """Test topic generation with actual data from database."""
    logger.info("\n" + "=" * 80)
    logger.info("TESTING WITH DATABASE DATA")
    logger.info("=" * 80)

    try:
        from src.models.database import get_db_cursor
        from datetime import datetime, timedelta

        # Get yesterday's date (default news date)
        news_date = datetime.now() - timedelta(days=1)
        news_date = news_date.replace(hour=0, minute=0, second=0, microsecond=0)

        logger.info(f"Fetching articles from DB for date: {news_date.date()}")

        with get_db_cursor() as cur:
            # Get articles with embeddings
            cur.execute(
                """
                SELECT article_id, title, summary
                FROM article
                WHERE news_date = %s
                  AND summary IS NOT NULL
                  AND embedding IS NOT NULL
                ORDER BY article_id
                LIMIT 20
                """,
                (news_date,)
            )
            articles = cur.fetchall()

        if not articles:
            logger.warning("âš ï¸  No articles found in database for testing")
            return False

        logger.info(f"Found {len(articles)} articles")

        # Create a single test cluster from these articles
        # Take first 5 as representative articles
        representative = [
            {
                "title": article['title'],
                "summary": article['summary'] or article['title']  # Fallback to title
            }
            for article in articles[:5]
        ]

        test_cluster = [{
            "cluster_id": 999,
            "representative_articles": representative
        }]

        logger.info(f"Testing with {len(representative)} representative articles...")

        payload = {
            "clusters": test_cluster,
            "top_n_keywords": 3,
            "keyphrase_ngram_range": [2, 4]
        }

        url = f"{AI_SERVICE_URL}/generate-topics"
        response = requests.post(url, json=payload, timeout=AI_SERVICE_TIMEOUT)

        if response.status_code == 200:
            result = response.json()
            topic = result['topics'][0]

            logger.info("âœ… DB data test SUCCESS")
            logger.info(f"\nğŸ“Œ Generated topic title: {topic['topic_title']}")
            logger.info("   Keywords:")
            for kw in topic['keywords']:
                logger.info(f"     - {kw['keyword']} (score: {kw['score']:.3f})")

            logger.info("\n   Source articles:")
            for i, article in enumerate(representative, 1):
                logger.info(f"     {i}. {article['title'][:60]}...")

            return True
        else:
            logger.error(f"âŒ DB test failed: {response.status_code}")
            logger.error(f"   Response: {response.text}")
            return False

    except Exception as e:
        logger.error(f"âŒ DB test error: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run all tests."""
    logger.info("\n" + "=" * 80)
    logger.info("KEYBERT INTEGRATION TEST")
    logger.info("=" * 80)
    logger.info(f"AI Service URL: {AI_SERVICE_URL}")
    logger.info(f"Timeout: {AI_SERVICE_TIMEOUT}s")
    logger.info(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 80)

    results = {
        "health": False,
        "basic_test": False,
        "db_test": False
    }

    # Test 1: Health check
    logger.info("\n[1/3] Health Check")
    results["health"] = test_health_check()

    if not results["health"]:
        logger.error("\nâŒ Service is not healthy. Skipping other tests.")
        return 1

    # Test 2: Basic topic generation
    logger.info("\n[2/3] Basic Topic Generation")
    results["basic_test"] = test_generate_topics()

    # Test 3: With database data
    logger.info("\n[3/3] Database Integration")
    results["db_test"] = test_with_db_data()

    # Summary
    logger.info("\n" + "=" * 80)
    logger.info("TEST SUMMARY")
    logger.info("=" * 80)
    logger.info(f"Health Check: {'âœ… PASS' if results['health'] else 'âŒ FAIL'}")
    logger.info(f"Basic Test: {'âœ… PASS' if results['basic_test'] else 'âŒ FAIL'}")
    logger.info(f"DB Test: {'âœ… PASS' if results['db_test'] else 'âŒ FAIL'}")
    logger.info("=" * 80)

    all_passed = all(results.values())
    if all_passed:
        logger.info("\nğŸ‰ All tests PASSED!")
        return 0
    else:
        logger.error("\nâŒ Some tests FAILED")
        return 1


if __name__ == "__main__":
    sys.exit(main())
